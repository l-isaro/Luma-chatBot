{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f20628a",
   "metadata": {
    "id": "5f20628a"
   },
   "source": [
    "\n",
    "# Luma: Domain-Specific Mental Health Chatbot (T5, TensorFlow, Hugging Face)\n",
    "\n",
    "**Goal:** Fine-tune a generative Transformer (T5-small) on a mental-health Q&A dataset to build a domain-specific chatbot that provides supportive, safe responses and rejects out-of-domain or unsafe requests.\n",
    "\n",
    "**Why this matters:** Mental health support requires careful, context-aware language. A domain-tuned generative model improves relevance and tone while adhering to safety boundaries.\n",
    "\n",
    "**Repo structure (suggested):**\n",
    "```\n",
    ".\n",
    "├── Luma_chatbot_refactored.ipynb   # this notebook\n",
    "├── app.py                          # Gradio UI for interactive demo\n",
    "├── README.md                       # How to run + results\n",
    "└── data/\n",
    "    └── mental_health_training.csv\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b8fd06",
   "metadata": {
    "id": "f1b8fd06"
   },
   "source": [
    "\n",
    "## 1. Dataset Collection & Preprocessing\n",
    "\n",
    "We use the provided dataset and perform preprocessing: lowercasing, whitespace & URL cleanup, and dropping empties. We also document tokenization choices (T5 tokenizer).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfa5c7f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "id": "bfa5c7f1",
    "outputId": "5555f22f-d9f2-4d9e-d404-76d96d8fffb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['question', 'answer', 'pattern', 'tag']\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 941,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 726,\n        \"samples\": [\n          \"I could use support for ashamed fact-28 during exams. What can I do?\",\n          \"i'm not good enough\",\n          \"It\\u2019s hard for me because of unable to focus goodbye at night. What can I do?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 228,\n        \"samples\": [\n          \"It\\u2019s okay to take this one step at a time\\u2014you\\u2019re doing your best. Low mood can make everything heavier\\u2014tiny, kind actions for yourself count. Name and notice: label what you feel, where you feel it in your body, and rate its intensity from 1\\u201310. If this keeps getting in the way of daily life, consider talking to a licensed professional. If you ever feel at risk of harm, please contact local emergency services or a crisis helpline available in your area.\",\n          \"Oh that's really great. I'd be willing to answer anything that I know about it.\",\n          \"I'm sorry to hear that. Just know that I'm here for you. Talking about it might help. Why do you think you don't have any friends?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pattern\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 726,\n        \"samples\": [\n          \"I could use support for ashamed fact-28 during exams. What can I do?\",\n          \"i'm not good enough\",\n          \"It\\u2019s hard for me because of unable to focus goodbye at night. What can I do?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tag\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 90,\n        \"samples\": [\n          \"therapy\",\n          \"scared\",\n          \"fact-19\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-dfea54fc-310b-440b-b7af-9af524c23cec\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>pattern</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what if i feel lonely</td>\n",
       "      <td>A lot of people are alone right now, but we do...</td>\n",
       "      <td>what if i feel lonely</td>\n",
       "      <td>fact-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i'm so angry</td>\n",
       "      <td>Would writing a draft message (that you don’t ...</td>\n",
       "      <td>i'm so angry</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>everyone is better than me</td>\n",
       "      <td>Let’s gently check the evidence for and agains...</td>\n",
       "      <td>everyone is better than me</td>\n",
       "      <td>worthless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i keep crying for no reason</td>\n",
       "      <td>Would talking through today help a little? I'm...</td>\n",
       "      <td>i keep crying for no reason</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nothing much</td>\n",
       "      <td>Oh I see. Do you want to talk about something?</td>\n",
       "      <td>nothing much</td>\n",
       "      <td>neutral-response</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dfea54fc-310b-440b-b7af-9af524c23cec')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-dfea54fc-310b-440b-b7af-9af524c23cec button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-dfea54fc-310b-440b-b7af-9af524c23cec');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-d0722b08-8ccb-4a3f-bd84-dfbd8ff927b5\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d0722b08-8ccb-4a3f-bd84-dfbd8ff927b5')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-d0722b08-8ccb-4a3f-bd84-dfbd8ff927b5 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                      question  \\\n",
       "0        what if i feel lonely   \n",
       "1                 i'm so angry   \n",
       "2   everyone is better than me   \n",
       "3  i keep crying for no reason   \n",
       "4                 nothing much   \n",
       "\n",
       "                                              answer  \\\n",
       "0  A lot of people are alone right now, but we do...   \n",
       "1  Would writing a draft message (that you don’t ...   \n",
       "2  Let’s gently check the evidence for and agains...   \n",
       "3  Would talking through today help a little? I'm...   \n",
       "4     Oh I see. Do you want to talk about something?   \n",
       "\n",
       "                       pattern               tag  \n",
       "0        what if i feel lonely           fact-30  \n",
       "1                 i'm so angry             anger  \n",
       "2   everyone is better than me         worthless  \n",
       "3  i keep crying for no reason               sad  \n",
       "4                 nothing much  neutral-response  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd, numpy as np, re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DATA_PATH = \"data/mental_health_training_expanded.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(\"Columns:\", list(df.columns))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0223ff6c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "id": "0223ff6c",
    "outputId": "d15e8a77-5958-45ea-8904-80f589cc1a21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using input column:  question\n",
      "Using target column: answer\n",
      "Rows kept: 941/941 (removed 0)\n",
      "Sample:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"i'm so angry\",\n          \"nothing much\",\n          \"everyone is better than me\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Would writing a draft message (that you don\\u2019t send) help release some of this?\",\n          \"Oh I see. Do you want to talk about something?\",\n          \"Let\\u2019s gently check the evidence for and against that thought. What facts support the kinder view?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-5a618f42-74c2-4727-b341-f36ceb2dcfd3\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what if i feel lonely</td>\n",
       "      <td>A lot of people are alone right now, but we do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i'm so angry</td>\n",
       "      <td>Would writing a draft message (that you don’t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>everyone is better than me</td>\n",
       "      <td>Let’s gently check the evidence for and agains...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i keep crying for no reason</td>\n",
       "      <td>Would talking through today help a little? I'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nothing much</td>\n",
       "      <td>Oh I see. Do you want to talk about something?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a618f42-74c2-4727-b341-f36ceb2dcfd3')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-5a618f42-74c2-4727-b341-f36ceb2dcfd3 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-5a618f42-74c2-4727-b341-f36ceb2dcfd3');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-3710b446-8c00-4db8-9c53-cd70ccefe305\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3710b446-8c00-4db8-9c53-cd70ccefe305')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-3710b446-8c00-4db8-9c53-cd70ccefe305 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                      question  \\\n",
       "0        what if i feel lonely   \n",
       "1                 i'm so angry   \n",
       "2   everyone is better than me   \n",
       "3  i keep crying for no reason   \n",
       "4                 nothing much   \n",
       "\n",
       "                                              answer  \n",
       "0  A lot of people are alone right now, but we do...  \n",
       "1  Would writing a draft message (that you don’t ...  \n",
       "2  Let’s gently check the evidence for and agains...  \n",
       "3  Would talking through today help a little? I'm...  \n",
       "4     Oh I see. Do you want to talk about something?  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Robust column selection + cleaning (refactor of your block) ---\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Pick columns robustly (uses common aliases)\n",
    "INPUT_ALIASES  = [\"question\", \"pattern\", \"text\", \"prompt\", \"input\"]\n",
    "TARGET_ALIASES = [\"answer\", \"response\", \"target\", \"label\", \"tag\", \"output\"]\n",
    "\n",
    "def pick_col(df, aliases, fallback):\n",
    "    cols_lower = {c.lower(): c for c in df.columns}\n",
    "    for a in aliases:\n",
    "        if a in cols_lower:\n",
    "            return cols_lower[a]\n",
    "    # try contains-based match (e.g., \"user_question\")\n",
    "    for a in aliases:\n",
    "        for c in df.columns:\n",
    "            if a in c.lower():\n",
    "                return c\n",
    "    # fallback (will raise if missing)\n",
    "    if fallback in df.columns:\n",
    "        return fallback\n",
    "    raise KeyError(\n",
    "        f\"None of {aliases} found in columns {list(df.columns)} and fallback '{fallback}' not present.\"\n",
    "    )\n",
    "\n",
    "input_col  = pick_col(df, INPUT_ALIASES,  \"question\")\n",
    "target_col = pick_col(df, TARGET_ALIASES, \"answer\")\n",
    "\n",
    "print(f\"Using input column:  {input_col}\")\n",
    "print(f\"Using target column: {target_col}\")\n",
    "\n",
    "# 2) Cleaning helpers\n",
    "URL_RE   = re.compile(r\"http\\S+|www\\.\\S+\", flags=re.IGNORECASE)\n",
    "SPACE_RE = re.compile(r\"\\s+\")\n",
    "\n",
    "def clean_text(x, lower=False):\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    s = str(x)\n",
    "    s = URL_RE.sub(\"\", s)\n",
    "    s = SPACE_RE.sub(\" \", s).strip()\n",
    "    return s.lower() if lower else s\n",
    "\n",
    "# 3) Subset, clean, and sanitize\n",
    "df = df[[input_col, target_col]].copy()\n",
    "df[input_col]  = df[input_col].map(lambda t: clean_text(t, lower=True))   # lower input only\n",
    "df[target_col] = df[target_col].map(clean_text)                            # keep target case\n",
    "\n",
    "# 4) Drop empties and duplicates\n",
    "before = len(df)\n",
    "df = df[(df[input_col] != \"\") & (df[target_col] != \"\")]\n",
    "df = df.drop_duplicates(subset=[input_col, target_col]).reset_index(drop=True)\n",
    "\n",
    "print(f\"Rows kept: {len(df)}/{before} (removed {before - len(df)})\")\n",
    "print(\"Sample:\")\n",
    "display(df.head(5))  # comment out if not in notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fc6f9d",
   "metadata": {
    "id": "81fc6f9d"
   },
   "source": [
    "\n",
    "## 2. Model & Tokenization (T5-small, TensorFlow)\n",
    "\n",
    "We use `T5-small` with the Hugging Face `transformers` library. We prefix inputs to guide the model (prompting) and create TensorFlow datasets for training and validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "916bd681",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368,
     "referenced_widgets": [
      "8c4488393d7545a284dc5ece70e63c25",
      "25a2eb042c264e5788933a0cb604053c",
      "cc0dc5bbe5304822bfc16e8bdfa9541c",
      "30a7b5297d7f48c98e53d9aa53abaaf4",
      "61fe5eb5c8944df289ae95aef2c7764f",
      "01339bfa1aa2494fa3be4f7d5dabe2b7",
      "05ecb7bf1e644265a1fe029c712527b0",
      "abe373272b04422eb67435c5e2e22959",
      "f346aba94c5d41b9ba220ef00d414621",
      "b3bc7b31d9554dc586bf4b8ffcd1584c",
      "fbba947081cb44078437d05897b260c2",
      "04bd1607e7954d2ab912f0fb8e042259",
      "fea947bb38d84d68aef62ab6ba77fe99",
      "2169efbf03dc443ba717919987fb8f1a",
      "3eff49761369440f89e93be50ed097c7",
      "155b2a8a48ea4547b98f2c384076577a",
      "e648ca7a26834b2580a717619594afb7",
      "2c8b796454794b3fab1365cacf2264f0",
      "63d4412aad744a7cacf7316bf4430589",
      "95b7514e2f19404da7898c637b147464",
      "e93d1be9bff9472995f533fd780ad932",
      "bba40eb392d34f068ad8fcf98dc96a6b",
      "16f8a0e5efe5418ab1175dbfb09b8ab1",
      "8d256a996d88433abfd0789afad0b909",
      "481728a2111a46649e5c76152bdc77a9",
      "7e8e415f37954880a4a40af1837242db",
      "4283fa2c1e564e9a9e85e575812d72ca",
      "05ce2374d19b4d53b25b49f3faeb328c",
      "3224890cfad94453a5a82b976b3d3996",
      "e2325af2c8cf48bb85f5040302a31579",
      "09901e48e6a646d7b14c532e23e5bf8d",
      "d8060a4aee234390a6d23a42e0b02814",
      "1ce7198bba084e768becb8dc778e57a5",
      "0c83789ac9b6470aadf4bbe8e1db72b2",
      "575c66ed79aa44a1b45f39b8f3015a27",
      "e7053536f5274a9abab816a73cfcf2d0",
      "f5dcd07ce8ce4b5890fbc3251ec94b60",
      "ca8ea582dc53414b8a7a905fa6bb85fb",
      "d81f8feb88ae479fac854695486d430e",
      "c611a9804a73452d8d4304f946574940",
      "d4da57c8693b4677918416627298774a",
      "bd29da0b70d644f68ebe0d41f7af2a9a",
      "a0bffc4c772a42a8b8e6df952294b32a",
      "e543e7b39d514fda9f168c2e5e8227dc",
      "6d579964f9b5465d9f00adcf2b1e62db",
      "595b3e78bc1c49eaa8578a9236915339",
      "79b4346f8c8d47b6abfa40d2078d4804",
      "7bfbef2e796d4278b577984bf40ca55d",
      "e062c308f10e403aba3f4549cb47c44a",
      "ccab508291be4ac59399ce916944d4e4",
      "8c428b7c063b4952aa54828f7d06f86b",
      "425c36b47a944f28bc2aee9e5f8f3b3f",
      "327ebdee358246559e3895dab1c22893",
      "557221d248024ce79a7c1389172667d1",
      "ca0542ca2ff24b04991a6e2a49fbbd40",
      "bd3b06dcf5e846b1bf6f30b813d75f38",
      "825e663723064decac70fce63a2693f1",
      "6712b67535de4ec0875052c58099b1fb",
      "ed3b563edf354029843dceeb1f0464a2",
      "4c1cc89b6d4e4b6a85becb4248ff0000",
      "25fd2326328440e39fdf4ea3b779f3e7",
      "a90695d4735e45b589e2a7a2abf15e9f",
      "768044498d534e95a30e59a9e4ee8ac6",
      "de29ab55eac34ec688e98778d595016f",
      "bab9c3d0a42a40ebb8bf31280482e3e4",
      "558289159ded4fbba98a85c67c8774e5"
     ]
    },
    "id": "916bd681",
    "outputId": "6290b63f-c19e-418a-b65d-8f8ba47001a3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c4488393d7545a284dc5ece70e63c25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04bd1607e7954d2ab912f0fb8e042259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f8a0e5efe5418ab1175dbfb09b8ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c83789ac9b6470aadf4bbe8e1db72b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d579964f9b5465d9f00adcf2b1e62db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/846 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4034: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3b06dcf5e846b1bf6f30b813d75f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/95 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Refactor of your tokenization + dataset block (PyTorch-compatible) ---\n",
    "# pip install -U datasets\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, DataCollatorForSeq2Seq\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model_name = \"google/flan-t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "max_input_len = 256\n",
    "max_target_len = 128\n",
    "PREFIX = \"mental health support: \"\n",
    "\n",
    "# 1) Build input/target lists\n",
    "inputs  = (PREFIX + df[input_col]).tolist()\n",
    "targets = df[target_col].tolist()\n",
    "\n",
    "# 2) Train/val split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    inputs, targets, test_size=0.1, random_state=42, stratify=None\n",
    ")\n",
    "\n",
    "# 3) HF Datasets from lists\n",
    "train_raw = Dataset.from_dict({\"src\": X_train, \"tgt\": y_train})\n",
    "val_raw   = Dataset.from_dict({\"src\": X_val,   \"tgt\": y_val})\n",
    "\n",
    "# 4) Tokenize -> input_ids, attention_mask, labels (-100 on pad)\n",
    "def preprocess(batch):\n",
    "    enc = tokenizer(batch[\"src\"], max_length=max_input_len, truncation=True)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(batch[\"tgt\"], max_length=max_target_len, truncation=True)\n",
    "    enc[\"labels\"] = labels[\"input_ids\"]\n",
    "    return enc\n",
    "\n",
    "train_ds = train_raw.map(preprocess, batched=True, remove_columns=train_raw.column_names)\n",
    "val_ds   = val_raw.map(preprocess,   batched=True, remove_columns=val_raw.column_names)\n",
    "\n",
    "# 5) Torch formatting (so Trainer can index tensors)\n",
    "cols = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "train_ds.set_format(type=\"torch\", columns=cols)\n",
    "val_ds.set_format(type=\"torch\", columns=cols)\n",
    "\n",
    "# 6) Collator for padding at batch time (used in Trainer later)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a253d26",
   "metadata": {
    "id": "0a253d26"
   },
   "source": [
    "\n",
    "## 3. Fine-tuning & Hyperparameter Exploration\n",
    "\n",
    "We compile the TF model; Transformers' TF models compute loss when labels are provided, so we set only the optimizer. We explore a **small grid** over learning rate and epochs and keep the best validation loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43c48d67",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 761,
     "referenced_widgets": [
      "727cbf220b404046a63b9e62cc5dd807",
      "7ad300a7802d4c208b623c97814cb563",
      "d2d9554786cd4ed282aa96faac0deb9d",
      "60a357b6e3b640a98000eab98548fa5c",
      "a4b5095232a7422a968be275963f2381",
      "2085098ed9954f14882dcec5ece6cf83",
      "15595307bb144d76b3c5a5cae2538ba6",
      "9fd44ae2bce845c0a6d24deebe7bc624",
      "541716a1d1cc4564b15103da68aabf3b",
      "54302833d0f74841aa4211b07074fe00",
      "2d38716ccb0a42d086874e90f2836eff",
      "de8aa768680c407f9c9e5ef67eab8a40",
      "b782d5b7c3f04f899b86164c2ed97b94",
      "add786c31ae44913a85b391dcba0754a",
      "aafbf12923b94714a90776244c8cae8b",
      "360253f5ac0e478c9199ae0aad787754",
      "0456953044764e268641bc26c89d8f72",
      "1201355ec7244b568f665ff303608852",
      "ee2ebe66d50d4554bb34060ffc3437e7",
      "733bcf5f5355415d82cfa76056cbc02a",
      "b16f0a31603f421cac0c72024965abcc",
      "9677f06322eb44c381f062f9b31928bb",
      "f9d860fcf05d47b4b8780d8f255b7b2f",
      "cc290e543af7462692db4e623022d506",
      "75b22d35907a4f67a1a0b8ebdd5cf033",
      "c43158dee796499ab8925f9b441e928f",
      "a26a7991f603441f97ab7f02df61fdcb",
      "42c2b926253d49f2bffe98c68bee6e83",
      "6eb22104938b4755bb0062631ab22dab",
      "0593f5e34c494ee79a77e5a6d137054b",
      "1b1f401a67564a87a5649924fab52458",
      "25931049f7b44587a87a439f67d4cdcd",
      "0e9174f0146f420fbf15cb5087d96707"
     ]
    },
    "id": "43c48d67",
    "outputId": "d7bc41f4-a132-4fca-d94c-ce969ed90a1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training with lr=3e-05, epochs=5 ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "727cbf220b404046a63b9e62cc5dd807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de8aa768680c407f9c9e5ef67eab8a40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d860fcf05d47b4b8780d8f255b7b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/data/data_collator.py:740: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n",
      "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='530' max='530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [530/530 04:01, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.474300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training with lr=3e-05, epochs=8 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='848' max='848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [848/848 06:26, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.424600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training with lr=5e-05, epochs=5 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='530' max='530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [530/530 04:02, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.235200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training with lr=5e-05, epochs=8 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='848' max='848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [848/848 06:29, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.187100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: {'val_loss': 0.8535082936286926, 'lr': 5e-05, 'epochs': 8}\n"
     ]
    }
   ],
   "source": [
    "# --- Refactored training block (PyTorch + Trainer) ---\n",
    "\n",
    "import itertools, numpy as np, torch, gc\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq,\n",
    "    TrainingArguments, Trainer, set_seed\n",
    ")\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def build_model():\n",
    "    return AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "def run_train(lr=5e-5, epochs=2, keep_model=False):\n",
    "    model = build_model()\n",
    "    collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=f\"runs/{model_name.replace('/','_')}_lr{lr}_ep{epochs}\",\n",
    "        learning_rate=lr,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        report_to=\"none\",\n",
    "        no_cuda=not torch.cuda.is_available(),\n",
    "    )\n",
    "\n",
    "    # Prefer `processing_class=` (newer) but fall back to `tokenizer=` (older)\n",
    "    try:\n",
    "        trainer = Trainer(\n",
    "            model=model, args=args,\n",
    "            train_dataset=train_ds, eval_dataset=val_ds,\n",
    "            data_collator=collator, processing_class=tokenizer\n",
    "        )\n",
    "    except TypeError:\n",
    "        trainer = Trainer(\n",
    "            model=model, args=args,\n",
    "            train_dataset=train_ds, eval_dataset=val_ds,\n",
    "            data_collator=collator, tokenizer=tokenizer\n",
    "        )\n",
    "\n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate()\n",
    "    val_loss = float(metrics[\"eval_loss\"])\n",
    "\n",
    "    if keep_model:\n",
    "        # keep the trained model in memory for immediate inference\n",
    "        return val_loss, metrics, model\n",
    "\n",
    "    # otherwise clean up between grid runs\n",
    "    del trainer, model\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    return val_loss, metrics, None\n",
    "\n",
    "search_space = {\"lr\": [3e-5, 5e-5], \"epochs\": [5, 8]}\n",
    "best = {\"val_loss\": float(\"inf\"), \"lr\": None, \"epochs\": None}\n",
    "histories = {}\n",
    "best_model = None\n",
    "\n",
    "for lr, epochs in itertools.product(search_space[\"lr\"], search_space[\"epochs\"]):\n",
    "    print(f\"\\n=== Training with lr={lr}, epochs={epochs} ===\")\n",
    "    # keep the model only if it beats the current best\n",
    "    val_loss, metrics, model = run_train(lr, epochs, keep_model=True)\n",
    "    histories[(lr, epochs)] = metrics\n",
    "    if val_loss < best[\"val_loss\"]:\n",
    "        # dispose previous kept model (if any) to save VRAM/RAM\n",
    "        if best_model is not None and torch.cuda.is_available():\n",
    "            del best_model\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        best.update({\"val_loss\": val_loss, \"lr\": lr, \"epochs\": epochs})\n",
    "        best_model = model\n",
    "    else:\n",
    "        # not best → free this one\n",
    "        del model\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "print(\"Best:\", best)\n",
    "\n",
    "# Optional: save the best model for inference later\n",
    "if best_model is not None:\n",
    "    save_dir = \"t5-small-mental-support-best\"\n",
    "    best_model.save_pretrained(save_dir)\n",
    "    tokenizer.save_pretrained(save_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b5803d",
   "metadata": {
    "id": "76b5803d"
   },
   "source": [
    "\n",
    "## 4. Evaluation (BLEU, ROUGE-L, F1, Perplexity) + Qualitative\n",
    "\n",
    "We generate on the validation set and compute common text-gen metrics. Perplexity is derived from validation loss: `exp(val_loss)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26fe7b71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582,
     "referenced_widgets": [
      "e82af34a302346f6ae153a9767d61924",
      "82548c6709434694933325617f122a2c",
      "3f36bae6553c4d77a673345798be2838",
      "b34401bdc96244ad9de821fecf18d261",
      "63806275677b4ec8b5c08c7fcb976058",
      "221a7fb5700b4293822af2e7d59d73d0",
      "f64fa6b4661a4ed582caeb7503f89ed6",
      "efdcdc80303c4a3babcea7fe5db9cf3f",
      "ac32aa6de09a443c8e79c822ebe2ceca",
      "97daa82ebf484876b361603ee9efd095",
      "9189a83327fa4cd6a4787fa305e74e06",
      "34741b617e3b414b823dd3e288d612cd",
      "2c8227593c5946a8a747f1b244e9fdb1",
      "fcb9948607064b4997b05c59e33629be",
      "f6165e955aa7451398248c3a1941a2a2",
      "d794be5ff5c046c5afabb7f1aa1c498e",
      "b95682f7ec1947aba5a1eb456335f0ed",
      "5a04c2835fe540cebc8c18dad884b68a",
      "829da686fb5d4827b7f1755525b2d2f2",
      "e7b40694322a43b79f1f1a656619b1f5",
      "1d613582e10c4efabe343b2547d8d18e",
      "d640767756ea4680982e029911dc7c50",
      "e34cadfbb69e488a88a823ee6a0c46aa",
      "69609c7f0d394c25abd5e74da5e4b7c1",
      "fa27a772baef4dfe8b536f8d8599b91a",
      "5400235b707a4755828a551b89cd2217",
      "61df3d6c033947ab825607fe4c92cc11",
      "0ef53b1eac71420ab62712edad5b273f",
      "fa6ca62bb0fc477d99536a3c385630c0",
      "3068e761b1ad4a1cbce8e66133f61e3e",
      "9c2e38493a2344d98cb17247c2f2da16",
      "2bb0d933f490421783456285dee35da1",
      "a5ff8a3423f9432a9396ac0dff4affe3",
      "9dd3b1fb58dc4130810c5d62cbc85018",
      "09389e9a34f947798f406edc0a9b00c2",
      "e55b2ff94d7e4b51adb52bfd6d4ed08d",
      "fda3780376db4abaa56675ac3a51d99c",
      "542071a8c52e45d184eaa122231efb9c",
      "3ebcc5eeb8974f618f5e28040d50b85a",
      "ac49250b6bea4b21aab081c3a839a103",
      "76d2a35f476a405ba99fbc6845a0fabf",
      "0aa24a438da14d0192716e6a905e54f0",
      "243175061e08452ea18f2f6639db8933",
      "138f940b2a3248559cff9227ad2fdbfc"
     ]
    },
    "id": "26fe7b71",
    "outputId": "55c29c72-e951-43aa-d17d-84ae77c64571"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82af34a302346f6ae153a9767d61924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34741b617e3b414b823dd3e288d612cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e34cadfbb69e488a88a823ee6a0c46aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dd3b1fb58dc4130810c5d62cbc85018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: {'bleu': 0.1520378840056875, 'precisions': [0.33830315938942135, 0.18111682586333577, 0.1606395127521888, 0.1528436018957346], 'brevity_penalty': 0.7719882552405887, 'length_ratio': 0.7944162436548223, 'translation_length': 2817, 'reference_length': 3546}\n",
      "ROUGE: {'rouge1': np.float64(0.2251221472984557), 'rougeL': np.float64(0.18905248646003192)}\n",
      "F1 (token-level) - mean: 0.2025087217296768\n",
      "Validation Perplexity: 2.347869435254632\n",
      "\n",
      "USER: mental health support: probably because my exams are approaching. i feel stressed out because i don't think i've prepared well enough.\n",
      "GOLD: I see. Have you taken any approaches to not feel this way?\n",
      "PRED: That sounds really tough, and it makes sense that you’re overwhelmed. Different strategies help different people—try small steps and notice what supports you best. Do a quick grounding check: look for 5 things you see, 4 you feel, 3 you hear, 2 you smell, 1 you taste. If this\n",
      "\n",
      "USER: mental health support: nobody understands me\n",
      "GOLD: It sound like i'm not being very helpful right now.\n",
      "PRED: I'm sorry to hear that. Talking about it can be helpful. I'm here for you.\n",
      "\n",
      "USER: mental health support: what's the difference between anxiety and stress\n",
      "GOLD: Stress and anxiety are often used interchangeably, and there is overlap between stress and anxiety. Stress is related to the same fight, flight, or freeze response as anxiety, and the physical sensations of anxiety and stress may be very similar. The cause of stress and anxiety are usually different, however. Stress focuses on mainly external pressures on us that we're finding hard to cope with. When we are stressed, we usually know what we're stressed about, and the symptoms of stress typically disappear after the stressful situation is over. Anxiety, on the other hand, isn't always as easy to figure out. Anxiety focuses on worries or fears about things that could threaten us, as well as anxiety about the anxiety itself. Stress and anxiety are both part of being human, but both can be problems if they last for a long time or have an impact on our well-being or daily life.\n",
      "PRED: Stress is a feeling of anxiety or irritability that arises from a physical or mental illness. Stress can be a combination of anxiety and depression, and can be a form of anxiety or depression. Stress can also be a form of anxiety or depression, and can be a form of\n",
      "\n",
      "USER: mental health support: am i depressed?\n",
      "GOLD: For a diagnosis of depression, a person needs to have experienced low mood or loss of interest or pleasure in life for at least 2 weeks. Also, they will have experienced the following symptoms: feelings of sadness, hopelessness, or irritability nearly every day.\n",
      "PRED: I’m really glad you reached out—what you’re feeling is valid. Different strategies help different people—try small steps and notice what supports you best. Schedule a 10-minute gentle walk or stretch to reset your nervous system. If you have access, a brief chat with a counselor can help you\n",
      "\n",
      "USER: mental health support: what do i do\n",
      "GOLD: It's only natural to feel this way. I'm here for you.\n",
      "PRED: I'm a professional counselor who works with adults and children. I'm here to help you find tools that fit you.\n"
     ]
    }
   ],
   "source": [
    "# --- EVAL BLOCK: BLEU, ROUGE, token-F1, perplexity (PyTorch) ---\n",
    "best = {'val_loss': 0.8535082936286926, 'lr': 5e-05, 'epochs': 8}\n",
    "\n",
    "import torch, numpy as np, nltk, evaluate\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 1) Load metrics\n",
    "bleu  = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "# 2) Get a model for inference (prefer the best fine-tuned one if available)\n",
    "try:\n",
    "    _has_best = 'best_model' in globals() and best_model is not None\n",
    "except NameError:\n",
    "    _has_best = False\n",
    "\n",
    "if _has_best:\n",
    "    model = best_model.to(device).eval()\n",
    "else:\n",
    "    from transformers import AutoModelForSeq2SeqLM  # local import to avoid reimport noise\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        \"t5-small\" if \"infer_model_path\" not in globals() else infer_model_path\n",
    "    ).to(device).eval()\n",
    "\n",
    "# 3) Generation helper (uses PT tensors)\n",
    "def generate_text(batch_inputs, max_new_tokens=64):\n",
    "    enc = tokenizer(\n",
    "        batch_inputs,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "    )\n",
    "    enc = {k: v.to(device) for k, v in enc.items()}\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(\n",
    "            **enc,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,   # deterministic; set True + temperature/top_p for sampling\n",
    "        )\n",
    "    return tokenizer.batch_decode(out, skip_special_tokens=True)\n",
    "\n",
    "# 4) Slice validation for speed\n",
    "val_slice = min(200, len(X_val))\n",
    "preds, refs = [], []\n",
    "bs = 16\n",
    "for i in range(0, val_slice, bs):\n",
    "    batch_inp = list(X_val[i:i+bs])     # ensure list[str]\n",
    "    batch_ref = list(y_val[i:i+bs])\n",
    "    batch_out = generate_text(batch_inp)\n",
    "    preds.extend(batch_out)\n",
    "    refs.extend([[r] for r in batch_ref])   # BLEU expects list[list[str]]\n",
    "\n",
    "# 5) Metrics\n",
    "bleu_res  = bleu.compute(predictions=preds, references=refs)\n",
    "rouge_res = rouge.compute(predictions=preds, references=[r[0] for r in refs])\n",
    "\n",
    "def f1_token(pred, ref):\n",
    "    ps, rs = pred.split(), ref.split()\n",
    "    if not ps or not rs: return 0.0\n",
    "    common = set(ps) & set(rs)\n",
    "    precision = sum(w in common for w in ps) / len(ps)\n",
    "    recall    = sum(w in common for w in rs) / len(rs)\n",
    "    return 0.0 if (precision + recall) == 0 else 2*precision*recall/(precision+recall)\n",
    "\n",
    "f1_scores = [f1_token(p, r[0]) for p, r in zip(preds, refs)]\n",
    "val_perplexity = float(np.exp(best[\"val_loss\"])) if np.isfinite(best[\"val_loss\"]) else None\n",
    "\n",
    "print(\"BLEU:\", bleu_res)\n",
    "print(\"ROUGE:\", {k: rouge_res[k] for k in [\"rouge1\", \"rougeL\"] if k in rouge_res})\n",
    "print(\"F1 (token-level) - mean:\", float(np.mean(f1_scores)))\n",
    "print(\"Validation Perplexity:\", val_perplexity)\n",
    "\n",
    "# 6) Qualitative examples\n",
    "for i in range(min(5, val_slice)):\n",
    "    print(\"\\nUSER:\", X_val[i])\n",
    "    print(\"GOLD:\", y_val[i])\n",
    "    print(\"PRED:\", preds[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "-FOFu8zRbZ4o",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-FOFu8zRbZ4o",
    "outputId": "8e7687f4-0782-49a2-da72-0e9cffa32015"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model_name\": \"google/flan-t5-base\",\n",
      "  \"learning_rate\": 5e-05,\n",
      "  \"epochs\": 8,\n",
      "  \"bleu\": 0.1520378840056875,\n",
      "  \"rouge1\": 0.2251221472984557,\n",
      "  \"rougeL\": 0.18905248646003192,\n",
      "  \"token_precision_mean\": 0.23994181519898058,\n",
      "  \"token_recall_mean\": 0.19238476296706686,\n",
      "  \"token_f1_mean\": 0.2025087217296768,\n",
      "  \"exact_match_accuracy\": 0.0,\n",
      "  \"val_perplexity\": 2.347869435254632\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json, numpy as np\n",
    "\n",
    "# token-level precision/recall/F1 + exact-match\n",
    "def token_pr_f1(pred, ref):\n",
    "    ps, rs = pred.split(), ref.split()\n",
    "    if not ps or not rs: return 0.0, 0.0, 0.0\n",
    "    common = set(ps) & set(rs)\n",
    "    p = sum(w in common for w in ps) / len(ps)\n",
    "    r = sum(w in common for w in rs) / len(rs)\n",
    "    f1 = 0.0 if (p + r) == 0 else 2*p*r/(p+r)\n",
    "    return p, r, f1\n",
    "\n",
    "prf = [token_pr_f1(p, r[0]) for p, r in zip(preds, refs)]\n",
    "token_precision_mean = float(np.mean([x[0] for x in prf]))\n",
    "token_recall_mean    = float(np.mean([x[1] for x in prf]))\n",
    "token_f1_mean        = float(np.mean([x[2] for x in prf]))\n",
    "exact_match_accuracy = float(np.mean([int(p.strip() == r[0].strip()) for p, r in zip(preds, refs)]))\n",
    "\n",
    "lr     = best.get(\"lr\") if \"best\" in globals() else None\n",
    "epochs = best.get(\"epochs\") if \"best\" in globals() else None\n",
    "val_perplexity = float(np.exp(best[\"val_loss\"])) if (\"best\" in globals() and np.isfinite(best[\"val_loss\"])) else None\n",
    "\n",
    "summary = {\n",
    "  \"model_name\": model_name,\n",
    "  \"learning_rate\": lr,\n",
    "  \"epochs\": epochs,\n",
    "  \"bleu\": float(bleu_res[\"bleu\"]),\n",
    "  \"rouge1\": float(rouge_res.get(\"rouge1\", 0.0)),\n",
    "  \"rougeL\": float(rouge_res.get(\"rougeL\", 0.0)),\n",
    "  \"token_precision_mean\": token_precision_mean,\n",
    "  \"token_recall_mean\": token_recall_mean,\n",
    "  \"token_f1_mean\": token_f1_mean,\n",
    "  \"exact_match_accuracy\": exact_match_accuracy,\n",
    "  \"val_perplexity\": val_perplexity\n",
    "}\n",
    "\n",
    "print(json.dumps(summary, ensure_ascii=False, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "TmPRQMO1WkpN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TmPRQMO1WkpN",
    "outputId": "71221237-8db5-430d-fd46-15abf41556d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rouge_score) (2.0.2)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.35.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.10.5)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (8.3.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=2ab948e834ee9e696c8ea0305254a50d59ca2e768d6634d42d1211c9733dedc0\n",
      "  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score, evaluate\n",
      "Successfully installed evaluate-0.4.6 rouge_score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae6d506",
   "metadata": {
    "id": "fae6d506"
   },
   "source": [
    "\n",
    "## 5. Inference Helper & Safety Guardrails\n",
    "\n",
    "We include a lightweight out-of-domain/unsafe detector and a safe fallback response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19af1b12",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "19af1b12",
    "outputId": "eb5273b3-a651-42fe-c3db-caa76bce7c63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel anxious about work -> I'm really glad you reached out—what you're feeling is valid. What support is available to you today?\n",
      "how to end my life? -> I'm here to help with supportive information about mental health, coping strategies, and resources. If you're in immediate danger, please contact local emergency services or a crisis hotline.\n"
     ]
    }
   ],
   "source": [
    "import re, torch\n",
    "\n",
    "PREFIX = \"mental health support: \"\n",
    "SAFE_FALLBACK = (\n",
    "    \"I'm here to help with supportive information about mental health, coping strategies, and resources. \"\n",
    "    \"If you're in immediate danger, please contact local emergency services or a crisis hotline.\"\n",
    ")\n",
    "\n",
    "# Stronger safety check (word boundaries + common variants)\n",
    "DANGER_RE = re.compile(\n",
    "    r\"\\b(suicide|self[-\\s]?harm|harm myself|hurt myself|kill myself|end my life|overdose|kill (someone|others)|harm (someone|others))\\b\",\n",
    "    re.I\n",
    ")\n",
    "\n",
    "def is_unsafe(text: str) -> bool:\n",
    "    return bool(DANGER_RE.search(text or \"\"))\n",
    "\n",
    "# Choose device automatically (CPU/GPU)\n",
    "_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(_device).eval()  # ensure model is on the right device\n",
    "\n",
    "def chat_respond(user_text: str) -> str:\n",
    "    # 1) Safety first\n",
    "    if is_unsafe(user_text):\n",
    "        return SAFE_FALLBACK\n",
    "\n",
    "    # 2) Build input\n",
    "    inp = PREFIX + (user_text or \"\")\n",
    "    enc = tokenizer(\n",
    "        [inp],\n",
    "        return_tensors=\"pt\",          # <-- PyTorch tensors (fixes the error)\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "    enc = {k: v.to(_device) for k, v in enc.items()}\n",
    "\n",
    "    # 3) Generate\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **enc,\n",
    "            max_new_tokens=64,\n",
    "            do_sample=False,           # deterministic (set True + temperature/top_p for sampling)\n",
    "            no_repeat_ngram_size=3,    # reduce repetition\n",
    "        )\n",
    "\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# Quick test\n",
    "for q in [\"i feel anxious about work\", \"how to end my life?\"]:\n",
    "    print(q, \"->\", chat_respond(q))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1889d5e7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1889d5e7",
    "outputId": "d5d6b44c-ebc2-4733-900c-95c2d14148b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data/luma_t5_tf\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MODEL_DIR = \"data/luma_t5_tf\"\n",
    "tokenizer.save_pretrained(MODEL_DIR)\n",
    "model.save_pretrained(MODEL_DIR)\n",
    "print(\"Saved to\", MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db68aaed",
   "metadata": {
    "id": "db68aaed"
   },
   "source": [
    "\n",
    "## 8. Conclusions & Next Steps\n",
    "\n",
    "- **What worked:** Domain prefixing + T5-small fine-tuning yields coherent, supportive responses.\n",
    "- **Improvements:** Expand dataset coverage (coping, referrals, boundaries), add stronger safety filters, and consider parameter-efficient tuning for speed.\n",
    "- **Deployment:** You can wrap `app.py` in a small Docker image and deploy to a VM or Hugging Face Spaces.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
